写程序的主要目标是让程序在所有可能的情况下正确工作，程序员必须写下清晰的代码不仅让自己明白而且也可以让别人看懂以便以后的修改。另一方面来说，很多场合下让程序运行快也是一个考虑，如果一个程序必须处理视频或者网络包，那么一个慢点程序就无法满足要求了，本章将探索如何通过几个程序优化让程序运行的更快。

写出高效程序需要程序需要有如下几点，首先必须选择合适的算法和数据结构，第二必须写出编译器可以有效优化的源代码，对于后者理解编译器的能力和局限性是很重要的，C语言中的某些特性例如运行指针运算和转换让编译器无法优化，第三种技术是将一个任务分成可并行计算的若干部分，在多核和多处理器的某种组合上进行。我们将把这方面内容写在第12章。

程序员需要在程序的实现和维护的简易程度与程序的运行速度之间做出权衡，我们给出了很多提高代码性能的技术，即使是最好的编译器也会受到优化blockers的限制，这些优化blockers就是程序行为中那些依赖于执行环境的方面。

优化程序的第一步是消除不必要的工作，让代码尽可能运行想要的任务。这包括消除不必要的函数调用，条件测试和内存引用，这些优化并不依赖于目标机器的任何属性，为了最大化程序性能，编译器和程序员都需要目标机器的模型，定义指令如何被处理以及各个操作的时序特性。例如编译器必须知道时间信息去决定是否运行多个指令还是由一些shift和add进行结合。现代电脑使用复杂技术处理机器级程序，并行执行很多指令可能会导致指令执行顺序不同于他们在程序出现的顺序。我们根据英特尔和AMD处理器的最新设计，提出了这种机器的高级模型。我们还设计了一个图形化的数据流符号，以可视化处理器的指令执行，我们可以用它来预测程序性能。

第二步就是利用处理器的能力提供指令级并行以同时执行多个指令，我们给出几个例子，减少了计算里不同部分对数据的依赖，增加了执行的并行度。以对大型程序优化讨论结束这一章，描述了code profilers的用法去测试一个程序性能的不同部分。我们把优化看作是一个以特定顺序转换代码的线性过程，其实这并没有这么简单。性能可能和处理器的设计细节相关，而我们对此了解很少。

研究程序的汇编代码是获得编译器和代码执行的方式之一，仔细研究循环内部是一个很好的开始，以识别因为过多的内存引用和寄存器使用引发的性能降低的属性，我们会回头修改源代码让程序有更好的实现。对于新手程序员来说，不断修改源代码以试图骗编译器生成高效的代码似乎很奇怪，但这确实是许多高性能程序的编写方式。与用汇编语言编写代码的方法相比，这种方法的好处是所产生的代码仍然可以在其他机器上运行。

# 5.1 优化编译器的能力和缺点

现代编译器有很多算法去决定什么值被计算和如何被使用，然后简化表达式，在不同地方使用一个计算，减少运算次数。大多数编译器如GCC给用户提供了控制编译水平的操作，例如使用-Og完成基础的优化，而- O1,- O2...会完成更高级的优化，这可以提高程序性能但是可能会增加程序大小使得程序在debug时可读性降低。我们一般只研究-O1的水平。

编译器必须给程序用安全的优化，这意味着优化后的程序行为和未优化的一样。为了理解判断程序是否安全转换了，考虑twiddle1和twiddle2两个例子。两者都对指针xp指向位置的值增加了两次yp的值。twiddle2显然更有效，它只需要三次内存引用即（读指针xp，读指针yp，写xp），而twiddle1需要六次。即使xp和yp相等，编译器也无法生成twiddle2的代码去优化twiddle1，两个指向一个内存位置的指针被称为aliasing，在进行安全优化时，编译器必须假设different pointers可能是aliased，例如对于指针变量p和q，下面的四行代码里t1的值取决于指针p和q是否引用。如果没被被aliased，那么t1值为3000，否则就是1000。这会导致主要的优化障碍，会限制编译器生成优化代码的机会，**如果一个编译器无法决定是否两个指针被aliased**，那么会假设两者都可能因此限制了优化。

第二种优化障碍是**由于函数调用**，考虑下面代码虽然产生相同结果，但是func2调用f一次，而func1调用f4次。下面考虑f的代码，其功能是修改全局变量counter。那么调用f次数的改变将会改变函数的行为，在全局变量counter为0的情况下，func1的调用会导致返回0+1+2+3=6，而函数2的调用会产生4*0=0的值。大多数编译器不会判断是否函数有副作用而是假设最坏的情况并保持函数调用不动。

GCC作为不错的编译器，不会像更 "激进 "的编译器那样对程序进行彻底的改造。因此，使用GCC的程序员必须投入更多的精力来编写程序，以简化编译器生成高效代码的任务。

# 5.2 展示程序性能

引入度量单位cycles per element，缩写为CPE，作为我们提高程序性能指标。CPE帮助我们理解迭代程序的循环性能。处理器的活动序列由一个时钟控制，这个时钟提供了一个规律的周期信号即GHZ，每秒数亿周期。例如某个4GHZ处理器就意味着处理器时钟每秒运行4*10^9周期。每个时钟周期时间就其倒数了。可以用nanoseconds或者picoseconds去表达时钟周期，这样更容易让程序员接受，这样的度量展示了有多少指令被执行而不是时钟周期运行的多快。

很多程序在一组数据上进行循环，例如图5.1的函数psum1和psum2都计算长度为n的向量的前缀和。函数psum1每次迭代产出结果的一个元素，而函数psum2使用loop unrolling去完成每次迭代计算两个元素。这样的程序运行时间可以由一个常数加一个与所处理的元素数量成比例的系数。例如图5.2展示了n个元素下两个函数的时间周期，使用**最小二乘法**可以获得psum1大约需要368+9n个周期而psum2需要368+6n个周期。这显示了需要368个周期完成初始化函数，设置循环等，再加上每个元素的处理周期即6或9周期。当n超过200的时候，整个运行时间就会受到6n和9n的影响。我们更喜欢测量每个元素的时间周期而不是每次迭代的时间周期，因为loop unrolling技术会让我们用更少的迭代去完成计算。我们聚焦于最小化计算的CPE，通过测量显然psum2优于psum1。

# 5.3 程序例子

为了展示一个程序如何被系统地转为更有效的代码，我们基于向量数据结构使用一个运行的例子，如图5.3所示，一个向量包含了内存的两块即头部和数组，定义见vec.h，声明使用data_t表示底层的数据元素。我们的评估里测量了代码针对int，long以及浮点数的性能，通过typedef int data_t这样的声明修改数据类型来达到此目的。

图5.4给出了生成向量，访问向量元素和决定向量长度的基本程序，一个重要的特征是get_vec_element会对向量引用进行边界检查，边界检查虽然降低了程序出错概率但是会降低程序执行速度。图5.5给出了优化的例子，它通过某个操作将向量元素变成一个值，通过使用IDENT和OP的定义，代码可被重新编译去运行数据的各种操作。比如IDENT等于0且OP等于+的时候代表向量求和，而IDENT为1且OP为乘的时候代表元素的product。我们运行运算在I7处理器上查看实验结果。

下面的表格展示了combine1的CPE，其结果结合了不同的操作和数据类型。我们对许多不同程序的实验表明，对32位和64位整数的操作具有相同的性能，但涉及除法操作的代码除外。从表格也可以看到优化后的代码所需要的时间周期更短。

# 5.4 消除无效循环

观察图5.5里的combine1函数，函数调用vec_length是循环的测试条件，回顾3.6.7里曾经提到过测试条件总是在每次循环都进行检查。而另一方面向量长度不会随着循环改变，因此可以一次计算向量长度然后在测试条件里使用这个值。图5.6给出了combine1的改良版本combine2，它调用vec_length后就获得一个局部变量length，这种转换对某些数据类型和操作的整体性能有明显的影响，而对其他数据类型和操作则影响很小，甚至没有影响。但是，在任何情况下，这种转换都是必要的，因为这可以消除低效率，而这些低效率会是优化的瓶颈。

上述优化其实是code motion优化类别的例子，即找到一个运行多次的计算，这个计算的结果哪怕多次运行也不会改变。因此可以将这个计算移动到代码前面的部分。注意程序员必须帮助编译器完成这样的改良，因为编译器非常的保守而不会去做这些转换。

考虑图5.7的lower1函数，这个函数的目的是把所有的大写字母转为小写，而库函数strlen是lower1循环测试的一部分。由于C的字符串是一个无休止的字符序列，因此strlen必须遇到null的时候才停止，故它的处理时间其实和长度成正比，因为strlen的调用是n次迭代，故lower1的总运行时间是长度的平方，即$n^2$。这样的分析得到了证实，如图5.8所示。函数lower2和lower1行为一样，只是从循环里移除了strlen调用，但是性能却极大增加了。

理想下，编译器应该可以发现这样无效的循环并移除，但是其实最复杂的编译器都无法做到这一点，虽然lower2和lower1只改动了一点，但是在大数据集下改良的性能就会变得很大。

# 5.5 减少函数调用

函数调用可以造成负担并阻塞程序优化，可以看到图5.6里的combine2里的get_vec_element在每个函数调用都被调用去获得下一个元素。函数检查了索引i和循环边界。假设我们给我们的数据类型增加了函数get_vec_start，这个函数返回了数组的开始地址，如图5.9所示。可以看到combine3的函数循环里没有函数调用，它没有通过函数调用获得数组元素而是直接访问数组。

从5.9下面的表可以看出，combine2到combine3似乎没有性能的提升。显然，相比调用get_vec_element，内循环的其他操作形成了性能瓶颈限制了性能。在5.11.2的部分我们会看到为啥combine2里的重复的边界检查不会导致性能惩罚。目前我们可以将这个转换作为提升性能的一个小转换。

# 5.6 消除不必要的内存引用

combine3的代码累加了dst指向的值，这可以通过看内部循环生成的汇编代码，我们可以看到double和乘请客下的情况。可以看到循环代码里指针dest对应的值存储在寄存器%rbx里，%rdx里保存了指向第i个数据元素的指针，即data+i。这个指针每次循环都加8，通过%rdx和%rax的对比来决定循环是不是中止，可以看到每次循环里累加的值都需要读取并写入到内存。这样的读写十分浪费，因为每次迭代开始从dest读取的值其实就是迭代结束写入的值。

图5.10里的combine4消除了不必要的读写，在循环里引入了一个临时变量acc去消除重复值，这带来了巨大的性能提升。也许有人会认为编译器可以自动转换combine3的代码将值放到寄存器里累加，正如combine4这样。事实上由于内存aliasing这两个函数会有不同的行为，下面给出了例子。可以发现combine3是每次都需要对数组的最后一个元素进行读取，这也是存放目的值的位置。而combine4通过引入中间变量acc杜绝了这样的情况，它是在最后一步才完成赋值的。

# 5.7 理解现代处理器

目前完成的优化并不依赖于机器的特性，而仅仅是通过减少函数调用并消除优化瓶颈进行的。我们必须理解利用microarchitecture的优化，我们可以应用一些基本的优化，改进很多类处理器。这里给出的方法可能不适用某些机器，但是对大多数机器都具有通用性。

为了理解性能提升的方式，我们需要对现代处理器的microarchitecture有了解，由于大量晶体管可以被集中在一个chip里，现代microprocessors应用了复杂的硬件去最大化了程序性能。这会导致实际的运算和代码相差很大，在代码层面，指令似乎是一次执行一条。而在实际的处理器里，大量的指令同时被评估，这样的现象被称为指令级并行。现代microprocessors的特征就是，处理器部署了复杂的架构，在其中多个指令可以并行执行，但是看起来像是序列化执行指令。

可以发现有两个不同的边界标志着程序的最大性能，第一个是**latency bound**，即很多操作必须以严格的顺序运行，因为单个运行的结果是下一个操作的输入，这样的依赖关系会限制处理器并行执行的能力。第二个是**throughput bound**，表示处理器单元的计算能力，这个边界会最终限制程序性能。

## 5.7.1 操作总览

图5.11给出了现代处理器的示意图，这里给出的图类似于INTEL处理器，这些处理器以superscalar的形式给出，这意味着他们可以在每个时钟周期以乱序运行多个操作。总的设计包括两个方面，第一个方面是**指令控制单元ICU**，负责从内存读取指令并根据这些原子操作运行程序数据。第二个方面是**执行单元EU**，它负责执行这些操作，和顺序的管道相比，乱序处理器需要更复杂的硬件，但它可以更好地完成指令级并行。

ICU从指令缓存里读取指令，指令缓存是一个包含了大多数最近访问指令的高速内存。一般来说，ICU会在当前指令执行之前获取信息，这样它就有足够的时间解码这些指令并将操作发送到EU。存在一个问题就是程序可能有分支，为此现代处理器应用了名为分支预测的技术，猜测分支是否被taken并预测分支的目的地址。使用一种被称为speculative execution的技术，处理器开始在其预测的分支位置获取和解码指令，甚至在确定分支预测是否正确之前就开始执行这些操作。如果预测是错误的，那么就会重置分支点的状态信息并开始从另一个方向取出和执行指令，图5.11里的Fetch control就整合了分支预测去运行决定哪个指令被取回的任务。

instruction decoding逻辑将实际的程序指令转换为一系列原子操作，每个操作运行一些简单的计算任务，对于复杂指令，X86-64回将其解码为多个操作。在一个x86实现里，操作数是寄存器的指令如addq %rax,%rdx会被转换为单个操作，而涉及一个或者多个内存引用的指令如addq %rax,8(%rdx)会有很多的操作：首先从内存加载一个值到处理器里，然后将加载的值放入到%eax里，然后将值写入内存。这样的解码可以让指令在一组专用的硬件单元之间进行分工。然后，这些单元可以并行地执行多条指令的不同部分。

EU从instruction fetch unit接受操作，一般每个时钟周期都会收到大量操作，这些操作被分配到一组执行实际操作的functional unit。内存的读写通过load unit和store unit实现，前者用于处理数据从内存到处理器的操作，后者处理数据从处理器到内存的操作，两者都有一个adder去进行地址计算。如图所示，两者都通过data cache访问内存，data cache是一个包含了最近使用数据值的高速内存。

使用speculative execution技术，操作被评估直到处理器确定这些指令应该被执行后，最后的结果才被存储在寄存器或者内存里，分支操作发给EU后，EU并不会决定哪个分支被执行而是去决定分支预测结果是否正确。如果预测错误，EU将会丢弃超出分支点计算的值并告知branch unit预测错误需要显示正确的分支。这样的情况下branch unit在新位置取指令。这样的错误预测会让性能有极大代价，因为新指令需要被取出，解码并发给functional units。

图5.11展示了不同functional units用于不同的操作。标记为arithmetic operations通常被用于运行不同的整数和浮点数操作。由于单个chip里晶体管数目的增加，微处理器的连续model增加了功能单元的总数，每个单元可以执行的操作组合，以及每个单元的性能。arithmetic unit被故意设计为可以进行多种操作，这是因为不同程序的计算需求是不同的，如果某个arithmetic unit被限定只能进行一种运算如整形运算，那么就会有一部分arithmetic unit得不到利用。

I7 HASWELL共有8个functional units，下面给出了每个unit的功能。

- 整数运算，浮点乘，整数以及浮点除，分支
- 整数运算，浮点加，整数乘，浮点乘
- 加载和地址计算
- 加载和地址计算
- 存储
- 整数运算
- 整数运算和分支
- 存储地址计算

在上面的列表里，整数运算指的就是加，按位操作和移位。乘除需要更多的资源，可以看到存储操作需要两个units，一个负责计算存储地址，另一个负责存储数据。可以看到functional units的结合给同时运行相同类型的多个操作提供可能，有4个单元可以运行整数操作，两个运行加载操作，另外两个运行浮点乘法。

在ICU内，retirement unit追踪了正在进行的进程并确保它遵守机器级的序列化。图里展示了包含整数，浮点数，SSE和AVX寄存器作为retirement unit的register file，retirement unit可以控制这些寄存器的更新。当一条指令被解码时，有关它的信息被放入队列中。在出现下列两种状况之前，信息都会保留在队列里，第一种情况下，一旦指令的操作完成，任何到这个指令的分支判断都会被认为是正确的，这个指令就是retired，之后会完成对程序寄存器的更新。而如果任何到这个指令的分支判断是错的，这个指令都会是flushed的，丢弃之前算的结果。任何对程序寄存器的更改都只发生在指令是retired的情况下，为了加快从一个指令到另一个指令的结果交流，许多信息在执行单元之间交换。执行单元之间交换信息，在图中显示为"Operation results"。如图中的箭头所示，各执行单元可以将结果直接发送给对方。

控制执行单元之间操作数通信机制被称为register renaming，当一个更新寄存器r的指令被解码后，一个标签t生成去唯一标识操作结果。(r,t)这样的条目被记录到表里，表负责维护寄存器r和标签t的关系，代表了更新寄存器r的操作。当后面的使用寄存器r为操作数的指令被解码时，发给execution unit的操作会将t视为源操作数。当一些execution unit完成第一个操作的时候会生成(v,t)，这显示带有标签t的操作产生了值v。任何等待t作为源的操作将使用v作为源值。通过这样的机制，值可以被从一个操作转发到另一个，而不是通过读写寄存器进行。整个表只包含有待写操作的寄存器的条目。当一条解码指令需要寄存器r，而这个寄存器没有相关的标签时，操作数就会直接从register file中检索出来。通过register renaming，整个操作序列可以被推测地执行。

## 5.7.2 functional unit性能

图5.12给出了I7处理器做运算的性能，包括了latency即运行操作所需要的总时间，issue time即相同类型下两个独立操作使用的最小时钟周期，capacity即处理这个操作的functional units。可以发现从整形到浮点操作，latency是在增加的。我们还看到，加法和乘法操作的issue time都是1，这意味着在每个时钟周期中，处理器可以启动一个新的操作。短issue time通过使用管道实现，一系列的stages将被用于实现一个pipelined function unit，比如一个浮点数增加包括了三个stages（所以latency为3个周期）， 一个处理指数值，一个是把分数相加，一个是把结果四舍五入。算术运算可以紧密连续地进行各个stages，而不是等待一个操作完成后再开始下一个操作。这样的行为只有当stages是连续的且操作之间是独立的才会出现，issue time为一个周期的functional unit被称为fully pipelined，因为它们可以在每个时钟周期开始一个新的操作。capacity大于1的操作由多个functional units产生。



